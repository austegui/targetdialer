---
phase: 01-foundation
plan: 04
type: execute
wave: 4
depends_on: ["01-03"]
files_modified:
  - apps/api/src/vexa_client.py
  - apps/api/src/webhook/vexa.py
  - apps/api/src/jobs/transcript.py
  - apps/api/src/jobs/health_check.py
  - apps/api/src/main.py
  - apps/web/src/app/api/calendar/webhook/route.ts
  - apps/web/src/lib/calendar/watcher.ts
autonomous: false

must_haves:
  truths:
    - "When a td_meetings row is created with status 'requested', the FastAPI service dispatches a Vexa bot to join that Google Meet"
    - "When a meeting ends, the Vexa webhook delivers transcript segments to the FastAPI service, which stores them immediately in td_transcript_segments"
    - "Transcript segments include timestamps, speaker labels, and text — all persisted in TargetDialer's own database"
    - "If a bot reports ACTIVE status but no transcript segments arrive within 3 minutes, an automatic health check triggers a restart and logs an alert"
    - "The bot dispatch flow is end-to-end: calendar event -> td_meetings row -> bot dispatch -> transcript storage"
  artifacts:
    - path: "apps/api/src/vexa_client.py"
      provides: "Thin wrapper around Vexa api-gateway HTTP endpoints"
      contains: "start_bot"
    - path: "apps/api/src/webhook/vexa.py"
      provides: "POST /webhook/vexa handler for meeting completion callback"
      contains: "vexa_meeting_complete"
    - path: "apps/api/src/jobs/transcript.py"
      provides: "ARQ job to persist transcript segments to td_transcript_segments"
      contains: "save_transcript_segments"
    - path: "apps/api/src/jobs/health_check.py"
      provides: "Health check job that detects deaf bots and triggers restart"
      contains: "check_bot_health"
  key_links:
    - from: "apps/web/src/lib/calendar/watcher.ts"
      to: "apps/api (FastAPI)"
      via: "HTTP POST to /dispatch/bot when meeting detected"
      pattern: "fetch.*dispatch.*bot|/dispatch"
    - from: "apps/api/src/main.py"
      to: "apps/api/src/vexa_client.py"
      via: "VexaClient.start_bot() called from dispatch endpoint"
      pattern: "start_bot"
    - from: "apps/api/src/webhook/vexa.py"
      to: "apps/api/src/jobs/transcript.py"
      via: "Enqueues save_transcript_segments ARQ job on webhook receipt"
      pattern: "save_transcript_segments"
    - from: "apps/api/src/jobs/health_check.py"
      to: "apps/api/src/vexa_client.py"
      via: "Calls VexaClient to restart deaf bots"
      pattern: "start_bot|stop_bot"
---

<objective>
Wire the Vexa bot integration: dispatch a bot when a meeting is detected, receive transcript segments via Vexa webhook, store them in TargetDialer's database, and implement the health check that detects and restarts deaf bots.

Purpose: This is where TargetDialer takes ownership of transcript data. Without this, meetings are detected but never recorded. The health check prevents the silent-failure scenario where a bot joins but captures nothing — the most dangerous failure mode in the system.

Output: End-to-end flow from calendar detection to transcript storage. Bot dispatch, webhook receiver, transcript persistence, and health check all operational.
</objective>

<execution_context>
@C:\Users\Gustavo\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Gustavo\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
@.planning/phases/01-foundation/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: VexaClient, bot dispatch endpoint, and webhook receiver with transcript persistence</name>
  <files>
    apps/api/src/vexa_client.py
    apps/api/src/webhook/vexa.py
    apps/api/src/jobs/transcript.py
    apps/api/src/main.py
    apps/web/src/lib/calendar/watcher.ts
    apps/web/src/app/api/calendar/webhook/route.ts
  </files>
  <action>
    **apps/api/src/vexa_client.py:**
    Create `VexaClient` class exactly as documented in the research:
    - Constructor: `__init__(self, base_url, api_key)` — base_url is `VEXA_API_URL` env var (e.g., `http://api-gateway:8056`), api_key is `VEXA_API_KEY`
    - `async start_bot(native_meeting_id, platform="google_meet", bot_name="TargetDialer Notes")` — POST to `{base_url}/bots` with JSON body `{ platform, native_meeting_id, bot_name }`, headers `{ "X-API-Key": api_key }`. Returns response JSON. Raise on HTTP error.
    - `async stop_bot(platform, native_meeting_id)` — DELETE to `{base_url}/bots/{platform}/{native_meeting_id}`. For health check restarts.
    - `async get_bot_status(platform, native_meeting_id)` — GET to `{base_url}/bots/{platform}/{native_meeting_id}`. Returns status dict.
    - `async get_transcript(platform, native_meeting_id)` — GET to `{base_url}/transcripts/{platform}/{native_meeting_id}`. Returns list of segment dicts.
    - `async set_webhook_url(webhook_url)` — POST to `{base_url}/webhook` with `{ "url": webhook_url }`. Call this on startup to register TargetDialer's webhook endpoint.

    Use `httpx.AsyncClient` for all HTTP calls. Store a reusable client instance (created in lifespan, stored on app state).

    **apps/api/src/main.py (UPDATE):**
    Update the existing FastAPI app:
    - Add lifespan handler that:
      1. Creates asyncpg connection pool (from 01-01)
      2. Creates VexaClient instance
      3. Registers the Vexa webhook URL: `await vexa_client.set_webhook_url(f"{PUBLIC_API_URL}/webhook/vexa")`
      4. Creates ARQ Redis connection pool
      5. Stores pool, vexa_client, arq_pool on app.state
      6. On shutdown: close all pools
    - Include the vexa webhook router
    - Add POST `/dispatch/bot` endpoint:
      - Accepts JSON: `{ "vexa_meeting_id": str, "platform": str }`
      - Calls `app.state.vexa_client.start_bot(vexa_meeting_id, platform)`
      - Updates td_meetings: set `botStatus = "joining"`, `botJoinedAt = NOW()`
      - Returns `{ "status": "dispatched" }`
      - If bot dispatch fails (HTTP error from Vexa), update td_meetings `botStatus = "failed"`, log error, return error
    - Add a simple auth check on /dispatch/bot: verify a shared API key (`INTERNAL_API_KEY` env var) to prevent unauthorized bot dispatches. The Next.js service will call this endpoint with the key.

    **apps/api/src/webhook/vexa.py:**
    Create the webhook receiver as documented in research:
    - POST `/webhook/vexa` handler
    - Parse the incoming JSON payload. **IMPORTANT:** Log the raw payload on first receipt — the exact schema is not 100% confirmed. Use defensive parsing:
      - Try to extract: `native_meeting_id`, `platform`, `segments` (list of transcript segment dicts)
      - If the payload format differs from expected, log a warning with the full payload and return 200 (never reject Vexa's webhook)
    - For each segment, validate expected fields: `text` (required), `speaker`, `start_time`, `end_time`, `session_uid`, `absolute_start_time`, `absolute_end_time`, `language`
    - Enqueue an ARQ job `save_transcript_segments` with the parsed data
    - Return `{ "status": "accepted" }` immediately (don't block the webhook on DB writes)

    **apps/api/src/jobs/transcript.py:**
    Create the ARQ job as documented in research:
    - `save_transcript_segments(ctx, vexa_meeting_id, platform, segments)`:
      1. For each segment: INSERT into td_transcript_segments with all fields mapped from Vexa format
      2. Use ON CONFLICT DO NOTHING for idempotency (composite key: vexa_meeting_id + start_time + speaker — or just skip if exact same text+time exists)
      3. UPDATE td_meetings: set `first_segment_at = COALESCE(first_segment_at, NOW())`, `segment_count = count`, `meeting_ended_at = NOW()`, `bot_status = 'completed'`
      4. Log: "Saved {N} transcript segments for meeting {meeting_id}"
    - Use the asyncpg pool from `ctx["db_pool"]`

    **Wire the Calendar Watcher to bot dispatch (UPDATE apps/web files):**

    In `apps/web/src/lib/calendar/watcher.ts`, update `detectAndDispatchMeetings`:
    - After creating a td_meetings row with status "requested", immediately call the FastAPI dispatch endpoint:
      ```typescript
      await fetch(`${process.env.API_URL}/dispatch/bot`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${process.env.INTERNAL_API_KEY}`,
        },
        body: JSON.stringify({
          vexa_meeting_id: meetingCode,
          platform: "google_meet",
        }),
      })
      ```
    - Add `API_URL` (e.g., `http://api:8000`) and `INTERNAL_API_KEY` to .env.example

    **Update .env.example:**
    Add:
    ```
    # Internal service communication
    API_URL=http://api:8000
    INTERNAL_API_KEY=generate-an-internal-key
    PUBLIC_API_URL=http://localhost:8000
    ```
  </action>
  <verify>
    1. FastAPI starts: `curl http://localhost:8000/health` — returns 200
    2. Dispatch endpoint exists: `curl -X POST http://localhost:8000/dispatch/bot -H "Content-Type: application/json" -H "Authorization: Bearer test" -d '{"vexa_meeting_id":"test","platform":"google_meet"}'` — returns response (may fail on Vexa connection, but should not 500 on route)
    3. Webhook endpoint exists: `curl -X POST http://localhost:8000/webhook/vexa -H "Content-Type: application/json" -d '{"native_meeting_id":"test","platform":"google_meet","segments":[]}'` — returns `{"status": "accepted"}`
    4. Python files have no syntax errors: `cd apps/api && python -m py_compile src/vexa_client.py && python -m py_compile src/webhook/vexa.py && python -m py_compile src/jobs/transcript.py`
    5. TypeScript compiles: `cd apps/web && npx tsc --noEmit`
  </verify>
  <done>
    VexaClient wraps all Vexa API calls. Bot dispatch endpoint receives meeting IDs from Calendar Watcher and starts Vexa bots. Vexa webhook receiver accepts meeting completion callbacks and enqueues transcript persistence jobs. Transcript segments are stored in td_transcript_segments with idempotent inserts. The full pipeline is wired: calendar event -> detection -> bot dispatch -> transcript storage.
  </done>
</task>

<task type="auto">
  <name>Task 2: Bot health check (deaf bot detection) and ARQ worker setup</name>
  <files>
    apps/api/src/jobs/health_check.py
    apps/api/src/jobs/worker.py
    apps/api/src/main.py
  </files>
  <action>
    **apps/api/src/jobs/health_check.py:**
    Create `check_bot_health(ctx)` — an ARQ periodic job:
    1. Query td_meetings for rows where:
       - `bot_status = 'active'`
       - `first_segment_at IS NULL`
       - `bot_joined_at < NOW() - INTERVAL '3 minutes'`
    2. For each "deaf" bot found:
       a. Log ALERT: "Bot for meeting {meeting_id} is ACTIVE but no segments received after 3 minutes — restarting"
       b. Call `vexa_client.stop_bot(platform, meeting_id)` to stop the deaf bot
       c. Call `vexa_client.start_bot(meeting_id, platform)` to re-dispatch
       d. Update td_meetings: `bot_status = 'restarting'`, increment a `restart_count` (add this column if not in schema — text type, default "0")
       e. If `restart_count > 2`: stop trying, set `bot_status = 'failed'`, log CRITICAL alert
    3. Return count of bots restarted

    **apps/api/src/jobs/worker.py:**
    Create the ARQ worker configuration:
    ```python
    from arq import create_pool, cron
    from arq.connections import RedisSettings
    from src.jobs.transcript import save_transcript_segments
    from src.jobs.health_check import check_bot_health
    import os
    import asyncpg

    async def startup(ctx):
        ctx["db_pool"] = await asyncpg.create_pool(os.environ["DATABASE_URL"])

    async def shutdown(ctx):
        await ctx["db_pool"].close()

    class WorkerSettings:
        functions = [save_transcript_segments]
        cron_jobs = [
            cron(check_bot_health, minute={0, 1, 2, 3}, second=0)  # Run every minute
        ]
        on_startup = startup
        on_shutdown = shutdown
        redis_settings = RedisSettings.from_dsn(os.environ.get("REDIS_URL", "redis://redis:6379"))
    ```

    The health check runs every minute (checking if any bot has been active for 3+ minutes without segments). The transcript save job runs on-demand when enqueued by the webhook handler.

    **Update docker-compose.yml:**
    Add a `worker` service that runs the ARQ worker:
    ```yaml
    worker:
      build: ./apps/api
      command: arq src.jobs.worker.WorkerSettings
      depends_on:
        postgres:
          condition: service_healthy
        redis:
          condition: service_healthy
      environment:
        - DATABASE_URL=${DATABASE_URL}
        - REDIS_URL=${REDIS_URL}
        - VEXA_API_URL=${VEXA_API_URL}
        - VEXA_API_KEY=${VEXA_API_KEY}
      networks:
        - meetrec
    ```

    **Update apps/api/src/main.py:**
    - In the dispatch endpoint, after bot dispatch succeeds, update td_meetings `bot_status = 'joining'`
    - Add a status update mechanism: when Vexa's bot transitions to 'active', update td_meetings. This can happen via:
      1. The dispatch response from Vexa may include initial status
      2. A periodic poll from the health check job (simplest for now)
    - In `check_bot_health`, also query Vexa for current bot status via `vexa_client.get_bot_status()` and update td_meetings accordingly. This keeps td_meetings.bot_status in sync with Vexa's actual state.

    **Schema update (if needed):**
    Add `restart_count` column to td_meetings:
    ```typescript
    restartCount: text("restart_count").default("0"),
    ```
    Run drizzle-kit push.
  </action>
  <verify>
    1. Worker starts: `cd apps/api && arq src.jobs.worker.WorkerSettings --check` (or similar ARQ validation)
    2. Health check function compiles: `python -m py_compile src/jobs/health_check.py`
    3. Docker compose validates with worker service: `docker compose config`
    4. `docker compose up -d` — worker service starts alongside api service
    5. Schema updated: `docker compose exec postgres psql -U meetrec -c "\d td_meetings"` shows restart_count column
  </verify>
  <done>
    ARQ worker runs as a separate Docker service processing transcript save jobs and periodic health checks. Deaf bot detection (ACTIVE status + no segments for 3 minutes) triggers automatic restart with max 2 retries. Bot status in td_meetings stays synchronized. Roadmap success criteria #5 met.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Complete Vexa integration: bot dispatch from calendar detection, webhook receiver for transcript segments, transcript persistence in TargetDialer's database, and deaf bot health check with automatic restart.
  </what-built>
  <how-to-verify>
    NOTE: Full end-to-end testing requires a running Vexa instance and a real Google Meet call. For this verification, test the individual components:

    1. Verify all services are running: `docker compose ps` — should show postgres, redis, web, api, worker
    2. Test the dispatch endpoint (will fail to reach Vexa, but should handle gracefully):
       ```
       curl -X POST http://localhost:8000/dispatch/bot \
         -H "Content-Type: application/json" \
         -H "Authorization: Bearer $(grep INTERNAL_API_KEY .env | cut -d= -f2)" \
         -d '{"vexa_meeting_id":"abc-defg-hij","platform":"google_meet"}'
       ```
       Expected: Error response mentioning Vexa connection failure (not a 500 crash)
    3. Test the webhook receiver with mock transcript data:
       ```
       curl -X POST http://localhost:8000/webhook/vexa \
         -H "Content-Type: application/json" \
         -d '{"native_meeting_id":"abc-defg-hij","platform":"google_meet","segments":[{"text":"Hello world","speaker":"Speaker 1","start_time":"0.0","end_time":"2.5","language":"en"}]}'
       ```
       Expected: `{"status": "accepted"}`
    4. After webhook test, check if transcript was saved (give worker a few seconds):
       ```
       docker compose exec postgres psql -U meetrec -c "SELECT * FROM td_transcript_segments;"
       ```
       Expected: One row with text "Hello world", speaker "Speaker 1"
    5. Verify health check logic exists and ARQ worker is running:
       ```
       docker compose logs worker --tail 20
       ```
       Expected: Worker startup logs, periodic health check runs
    6. Check the full data flow in the database:
       ```
       docker compose exec postgres psql -U meetrec -c "SELECT vexa_meeting_id, bot_status, segment_count FROM td_meetings;"
       ```
  </how-to-verify>
  <resume-signal>Type "approved" if the dispatch, webhook, and transcript storage work correctly, or describe any issues. Full end-to-end testing with a real Vexa instance and Google Meet call can be deferred to integration testing.</resume-signal>
</task>

</tasks>

<verification>
1. VexaClient connects to Vexa api-gateway (or handles connection failure gracefully)
2. Bot dispatch creates/updates td_meetings rows
3. Vexa webhook receives completion payloads and enqueues transcript jobs
4. Transcript segments are persisted in td_transcript_segments
5. Health check detects deaf bots (ACTIVE + no segments after 3 min) and restarts them
6. ARQ worker runs as a Docker service processing jobs
7. End-to-end data flow: calendar event -> td_meetings row -> bot dispatch -> transcript webhook -> td_transcript_segments
</verification>

<success_criteria>
- REC-01 satisfied: Vexa bot joins Google Meet (via dispatch from Calendar Watcher)
- REC-02 satisfied: Real-time transcription with timestamps and speaker diarization stored
- REC-03 satisfied: Transcripts stored in TargetDialer's own database (td_transcript_segments)
- CAL-02 fully satisfied: System auto-dispatches Vexa bot to join detected meetings
- Roadmap success criteria #4 met: Full transcript with timestamps and speaker labels stored in TD's database
- Roadmap success criteria #5 met: Health check triggers restart and logs alert for deaf bots
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-04-SUMMARY.md`
</output>
